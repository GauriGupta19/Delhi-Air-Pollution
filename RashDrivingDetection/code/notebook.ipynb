{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d46d680-7dc1-4f8b-99d9-20bbdff383d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sys import argv\n",
    "from os import path\n",
    "from enum import Enum\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c825b64f-cc3e-421f-8953-14feb5dd163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "NUMEXEC = 10\n",
    "NUMFOLD = 10\n",
    "SEEDFACTOR = 10\n",
    "DATASET = '../dataset/'\n",
    "RESULT = '../result/'\n",
    "FRAMES = [4,5,6,7,8]\n",
    "DATASETTYPE = 'va'\n",
    "RESULTFILE = 'results.csv'\n",
    "LEARNINGRATE = 0.01\n",
    "BATCHSIZE = 10\n",
    "HIDDENSIZE = 10\n",
    "TESTFRAC = 0.1\n",
    "\n",
    "PARAM = \"-L 0.3 -M 0.2 -N 500 -V 0 -S %%SEED%% -E 20 -H %%HIDDEN_LAYERS%%\"\n",
    "HIDDENLAYER = [\"a\", \"40\", \"30\", \"20\", \"10\"]\n",
    "\n",
    "class CoordinateEnum(Enum):\n",
    "    X = 'X'\n",
    "    Y = 'Y'\n",
    "    Z = 'Z'\n",
    "\n",
    "class Sensor:\n",
    "    def __init__(self, name, key, *argv):\n",
    "        self.name = name\n",
    "        self.key = key\n",
    "        self.coordinates = list(argv)   \n",
    "\n",
    "class SensorEnum(Enum):\n",
    "\tLINEAR_ACCELERATION_EARTH = Sensor(\"aceleracaoLinearTerra\", \"AclLinE\", CoordinateEnum.X, CoordinateEnum.Y, CoordinateEnum.Z)\n",
    "\tACCELEROMETER_EARTH = Sensor(\"acelerometroTerra\", \"AcelE\", CoordinateEnum.X, CoordinateEnum.Y, CoordinateEnum.Z)\n",
    "\tMAGNETIC_FIELD_EARTH = Sensor(\"campoMagneticoTerra\", \"MagE\", CoordinateEnum.Y, CoordinateEnum.Z)\n",
    "\tGYROSCOPE_EARTH = Sensor(\"giroscopioTerra\", \"GirE\", CoordinateEnum.X, CoordinateEnum.Y, CoordinateEnum.Z)\n",
    "\n",
    "class EventEnum(Enum):\n",
    "    AGGRESSIVE_LEFT_TURN = \"curva_esquerda_agressiva\"\n",
    "    AGGRESSIVE_RIGHT_TURN = \"curva_direita_agressiva\"\n",
    "    AGGRESSIVE_LEFT_LANE_CHANGE = \"troca_faixa_esquerda_agressiva\"\n",
    "    AGGRESSIVE_RIGHT_LANE_CHANGE = \"troca_faixa_direita_agressiva\"\n",
    "    AGGRESSIVE_ACCELERATION = \"aceleracao_agressiva\"\n",
    "    AGGRESSIVE_BRAKE = \"freada_agressiva\"\n",
    "    NON_AGGRESSIVE = \"evento_nao_agressivo\"\n",
    " \n",
    "events = {'curva_esquerda_agressiva': 0, \n",
    "          'curva_direita_agressiva': 1, \n",
    "          'troca_faixa_esquerda_agressiva': 2, \n",
    "          'troca_faixa_direita_agressiva': 3, \n",
    "          'aceleracao_agressiva': 4, \n",
    "          'freada_agressiva': 5, \n",
    "          'evento_nao_agressivo': 6\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd68be9a-901e-4243-978d-6639d1811a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierExecuter:\n",
    "    def __init__(self,*argv) -> None:\n",
    "        if(len(argv) > 1):\n",
    "            sensor,coordinate,hiddenLayers,numframes,seeds = argv\n",
    "            self.sensor = sensor\n",
    "            self.coordinate = coordinate\n",
    "            self.Param = PARAM.replace(\"%%HIDDEN_LAYERS%%\",hiddenLayers)\n",
    "            self.numframes = numframes\n",
    "            self.seeds = seeds\n",
    "            self.isDir = True\n",
    "        else:\n",
    "            filename = argv[0]\n",
    "            self.file = filename\n",
    "            self.isDir = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f3b1127-98dd-4a0c-a17d-726e85f63a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecordHandler:\n",
    "    def __init__(self,values,events):\n",
    "        self.values = values\n",
    "        self.events = events\n",
    "        self.numClasses = len(events)\n",
    "        self.inputSize = values[0][:-2].size\n",
    "    \n",
    "    def segregate(self, testFrac):\n",
    "        \n",
    "        np.random.shuffle(self.values)\n",
    "    \n",
    "        features = torch.Tensor(\n",
    "            np.array( [i[:-2].astype(np.float32) for i in self.values])\n",
    "        )\n",
    "        \n",
    "        labels = torch.Tensor(\n",
    "            np.array( [ self.events[i[-1]] for i in self.values])\n",
    "        ).type(torch.LongTensor)\n",
    "        \n",
    "        #TODO: Also store quadro0 for future refrences (giving results)\n",
    "        \n",
    "        testSize = int(testFrac*len(features))\n",
    "        \n",
    "        self.testFeatures = features[:testSize]\n",
    "        self.testLabels = labels[:testSize]\n",
    "        \n",
    "        self.trainFeatures = features[testSize:]\n",
    "        self.trainLabels = labels[testSize:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e0d85f0-812e-4149-9031-1b37c96bae25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, inputSize, hiddenSize, numClasses) -> None:\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(inputSize,hiddenSize)\n",
    "        self.l2 = nn.Linear(hiddenSize,hiddenSize)\n",
    "        self.l3 = nn.Linear(hiddenSize,hiddenSize)\n",
    "        self.l4 = nn.Linear(hiddenSize,numClasses)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))\n",
    "        x = self.l4(x)\n",
    "        return F.log_softmax(x,dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97136af7-053f-4056-a91b-7292439362a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # train\n",
    "    for epoch in range(NUMEXEC):\n",
    "        batch_loss = 0\n",
    "        for i in tqdm(range(0, len(handler.trainFeatures), BATCHSIZE)): \n",
    "\n",
    "            features = handler.trainFeatures[i:i+BATCHSIZE].view(-1,handler.inputSize)\n",
    "            labels = handler.trainLabels[i:i+BATCHSIZE]\n",
    "\n",
    "            net.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            outputs = net(features)\n",
    "#             print(outputs)\n",
    "            loss = F.nll_loss(outputs,labels)\n",
    "#             print(outputs)\n",
    "#             print(labels)\n",
    "#             print()\n",
    "#             loss = nn.CrossEntropyLoss()\n",
    "#             loss = loss(outputs,labels)\n",
    "\n",
    "            # backward\n",
    "            loss.backward()    \n",
    "            optimizer.step()\n",
    "            batch_loss = batch_loss + loss\n",
    "        print(batch_loss)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17adfa1d-1474-4096-a985-6c228494b95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictTest():\n",
    "    # test\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        samples = 0\n",
    "\n",
    "        for i in range(len(handler.testFeatures)):\n",
    "            features = handler.testFeatures[i].view(-1,handler.inputSize)\n",
    "            label = handler.testLabels[i]\n",
    "\n",
    "            output = net(features)\n",
    "            if(torch.argmax(output) == label):\n",
    "                correct += 1\n",
    "            samples += 1 \n",
    "\n",
    "        acc = 100.0 * correct /samples\n",
    "        print(f'accuracy = {acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e814473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictTrain():\n",
    "    # test\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        samples = 0\n",
    "\n",
    "        for i in range(len(handler.trainFeatures)):\n",
    "            features = handler.trainFeatures[i].view(-1,handler.inputSize)\n",
    "            label = handler.trainLabels[i]\n",
    "\n",
    "            output = net(features)\n",
    "#             print(torch.argmax(output))\n",
    "            if(torch.argmax(output) == label):\n",
    "                correct += 1\n",
    "            samples += 1 \n",
    "\n",
    "        acc = 100.0 * correct /samples\n",
    "        print(f'accuracy = {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46e00e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#         TESTING\n",
    "# for i in FRAMES:\n",
    "#     for j in SensorEnum:\n",
    "#         path = f'../datasets/va_{j.value.name}_nq{i}.csv'\n",
    "#         file = pd.read_csv(path)\n",
    "#         values = file.values\n",
    "#         handler = RecordHandler(values,events)\n",
    "#         handler.segregate(TESTFRAC)\n",
    "#         net = NeuralNet(handler.inputSize, HIDDENSIZE, handler.numClasses)\n",
    "#         optimizer = optim.Adam(net.parameters(),lr = LEARNINGRATE) \n",
    "#         train()\n",
    "#         predictTrain()\n",
    "#         predictTest()\n",
    "#         print(i,j)\n",
    "\n",
    "        \n",
    "path = f'../datasets/va_acelerometroTerra_nq8.csv'\n",
    "file = pd.read_csv(path)\n",
    "values = file.values\n",
    "handler = RecordHandler(values,events)\n",
    "handler.segregate(TESTFRAC)\n",
    "net = NeuralNet(handler.inputSize, HIDDENSIZE, handler.numClasses)\n",
    "optimizer = optim.Adam(net.parameters(),lr = LEARNINGRATE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9278e797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 468.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(91.1998, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 467.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(75.7058, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 415.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(66.0994, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 518.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(59.3634, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 508.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(54.2002, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 518.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(50.0278, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 453.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(44.6748, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 437.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(39.8969, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 413.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(37.0677, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 486.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(35.2787, grad_fn=<AddBackward0>)\n",
      "accuracy = 69.97971602434077\n",
      "accuracy = 68.51851851851852\n"
     ]
    }
   ],
   "source": [
    "train()\n",
    "predictTrain()\n",
    "predictTest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa254cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632001cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
